---
layout:     post
title:      物体避障（jetbot）
subtitle:   jetbot
date:       2021-1-21
author:     BY Bigboss
header-img: img/rose-4776198_1920.jpg
catalog: 	 true
tags:
    - jetbot
---
# 物体避障（jetbot）

​	首先展示一下自己做的jetbot，这是nvidia公司的一个开源项目，具体细节可以参考https://github.com/NVIDIA-AI-IOT/jetbot

![](https://ftp.bmp.ovh/imgs/2021/02/f42d4fd1c7eac868.jpg)

​	电路图如下：

![](https://ftp.bmp.ovh/imgs/2021/02/6956bb6437789730.png)

## 概述

​	使用到的基本的工具集包括Pytorch & torchvision 、Opencv3 & Numpy 以及cuda 。Pytorch是Facebook开源的一个在深度学习领域有强大功能的工具包，用它来搭建和训练神经网络；Torchvision是Pytorch的伴随工具包，它包含了许多数据集加载方法和模型加载方法以及其他许多辅助功能。Opencv3 主要用于对图像的简单处理，例如色彩模式的调节，图像大小格式的调节，使得获取的图片能够符合模型的输入标准；Cuda 是调用GPU的工具，通过它可以让GPU计算训练过程，加快计算速度，减少训练时间。

​	芯片方面选择的是 NVIDIA 公司的 jetson nano 深度学习开发板，用它来运行我们训练好的模型和控制电机、摄像头等硬件设备。使得小车能够实现基本的前后左右的行走，拍摄图像的功能，以及自主运行过程中的自动避障、智能跟随人类的功能。通过nano可以控制电机的驱动，从而控制左右两个电机的运行状态，来达到基本的动作实现的目标。

​	接下来介绍一下避障方面

## 数据采集

​	为了让小车实现避障，我们需要进行相应数据的采集，最重要的是对照片进行采集，我们将小车放到实验室环境中，拍摄小车处于安全和危险两种状态下的照片，其中安全的意思是小车可以前行，危险的照片是在摄像头中出现这种情形时是不能继续前行的状态，分别放入两个文件夹中，命名为‘’free‘’和‘’blocked‘’，进行压缩后进行模型训练。

## 模型训练

​	解压后的照片会分为训练集和测试集，其中训练集用于训练模型，测试集的数据用于分析模型的准确度。torchvision提供了一系列我们可以使用的经过训练的模型。在一个被称为迁移学习的过程中，我们可以重新使用一个预先训练过的模型(在数百万张图像上训练过)，来完成一个可能没有那么多可用数据的新任务。在训练前模型的原始训练中学习到的重要特征在新的任务中可以重复使用。

​	我们选用的是alexnet模型，alexnet模型最初是为有1000个类标签的数据集训练的，但是我们的数据集只有两个类标签，我们将用一个新的、未经训练的、只有两个输出的层替换最终的层。

​	最终，我们在GPU上面进行网络的训练，下面是我进行训练的时候得到的数据，可以看到只是几次训练后模型的精准度就很高，原因可能是我进行训练的数据太少了。

![](https://ftp.bmp.ovh/imgs/2021/02/b4262bf1ab2d58c3.png)

![](https://ftp.bmp.ovh/imgs/2021/02/21dd3836be60dc1a.png)

## 实现避障

​	首先从之前得到的文件里面加载训练的权重，在将CPU中的权重加载到GPU的时候要创建预处理函数，这样参数才能匹配。接着初始化摄像头，当判断目前位置处于‘’blocked‘’时，小车左转，躲避障碍。

## 总结

​	我们通过这样的算法实现的避障一定程度上可以自己认为定义危险，更加智能的实现了避障的功能，比如在‘’blocked‘’文件中加入桌边的图片时，小车会实现防坠落的功能，这样的功能是普通机器用过红外线等外设所实现不了的。



